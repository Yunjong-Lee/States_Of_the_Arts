# [테슬라 오토파일럿 판결로 보는 SW안전 시사점]()

- summary  
소프트웨어 정의 차량(SDV)과 자율주행 기술 확산에 따라, 자동차 안전의 중심이 기계적 하드웨어에서 소프트웨어 및 데이터로 이동하고 있다.
특히 자율주행 및 첨단 운전자 보조 시스템(ADAS)의 상용화가 가속화되면서 전통적인 소프트웨어 기능안전 영역의 확대/재편되고 있다.

- 테슬라 오토파일럿(Autopilot) 사례
  + 정지 차량 충돌 사고(2019년 플로리다주)와 플로리다 남부연방지방법원의 손해배상 판결(Barrett v. Tesla, Inc., Case No. 1:21-cv-21940-BB) 사례 뷴석.
  + 차량은 오토파일럿 모드로 주행 중 정지 차량 미인식, AEB이 작동하지 못한 상태에서 운전자의 부주의가 겹치며 제3자 보행자 사망 및 중상 피해 발생.
  + 배심원단은 운전자 과실 67%, 테슬라 과실 33% 인정 및 2억 달러의 징벌적 손해배상을 추가 부과(사고 데이터 미제출·은폐의혹, 과장된 마케팅 등을 근거).  
    ※ L-2 (SAE 기준) 시스템에 대해서도 제조사가 예측 가능한 오사용 방지 의무와 정보 제공·데이터 투명성 의무 부담을 명시적으로 확인한 첫 사례.  

- 오토파일럿 사고의 쟁점을 ISO 26262(기능안전), ISO 21448(SOTIF), ISO/PAS 8800(AI 안전) 등 국제 표준의 관점에서 해석
  + ISO􀀁 26262: E/E 시스템 고장(Fault)을 전제로 안전무결성을 관리하는 반면, SOTIF는 센서 인식 한계·환경적 모호성·사용자 오용 등 결함 없는 상태에서도 발생하는 위험을 다루며,
  + ISO/PAS􀀁 8800: AI·ML 기반 알고리즘의 데이터 품질·모델 불확실성을 포괄하는 안전 프레임워크 제시   
  ※ UNECE R157(ALKS), R171(DCAS) 등 국제 규정도 검토

- 테슬라 오토파일럿 판결은 소프트웨어 안전이 기술 내부의 “품질 이슈”가 아니라, 제조물 책임·징벌적 손해배상·데이터 투명성·AI 안전을 아우르는 종합적 리스크 관리 대상임을 보여준다.
- 생명·신체와 직결된 산업 전반에서 디지털 전환이 가속화될 때 최소 공통 SW 안전 요구사항으로서「소프트웨어 안전에 관한 고시」와 같은 지침 참고 필요 & Safety-Security 연계 ‘디지털 안전’ 차원의 거버넌스 검토 등
